# Auditel v3.0 ğŸš€

**Auditel** es un sistema inteligente de anÃ¡lisis normativo para fiscalizaciÃ³n pÃºblica, con **web scraping funcional** que extrae normativas actualizadas de fuentes oficiales.

## âœ¨ CaracterÃ­sticas Principales

### ğŸŒ Web Scraping Funcional
- **ExtracciÃ³n automÃ¡tica** de normativas del DOF y PeriÃ³dico Oficial de Tlaxcala
- **BÃºsqueda en tiempo real** de leyes, decretos y acuerdos
- **CachÃ© inteligente** con expiraciÃ³n de 24 horas
- **BÃºsqueda paralela** en mÃºltiples fuentes simultÃ¡neamente

### ğŸ” BÃºsqueda HÃ­brida Inteligente
- Combina datos locales (JSON) con web scraping
- Motor TF-IDF con similitud de coseno
- ExtracciÃ³n automÃ¡tica de referencias legales
- Procesamiento avanzado de texto

### ğŸ—ï¸ Arquitectura Modular
- CÃ³digo organizado en mÃ³dulos especializados
- FÃ¡cil mantenimiento y extensiÃ³n
- Scrapers extensibles para nuevas fuentes
- Sistema de cachÃ© persistente

### ğŸ“Š API REST Completa
- Endpoints para consultas normativas
- GestiÃ³n de cachÃ©
- Pruebas de web scraping
- EstadÃ­sticas del sistema

## ğŸ¯ Fuentes de Datos

### Fuentes Locales
- Base de datos JSON de Obra PÃºblica
- Base de datos JSON Financiera

### Fuentes Web (Scraping Activo)
- âœ… [Diario Oficial de la FederaciÃ³n (DOF)](https://www.dof.gob.mx/)
- âœ… [PeriÃ³dico Oficial del Estado de Tlaxcala](https://periodico.tlaxcala.gob.mx/)
- ğŸ”œ CÃ¡mara de Diputados (prÃ³ximamente)
- ğŸ”œ Suprema Corte de Justicia (prÃ³ximamente)

## ğŸš€ InstalaciÃ³n y Uso

### 1. Clonar repositorio

```bash
git clone https://github.com/tu-usuario/auditel.git
cd auditel
```

### 2. Crear entorno virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux / macOS
venv\Scripts\activate     # Windows
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar variables de entorno (opcional)

```bash
cp .env.example .env
# Editar .env con tu configuraciÃ³n
```

### 5. Ejecutar pruebas

```bash
python test_scraping.py
```

### 6. Iniciar aplicaciÃ³n

```bash
# VersiÃ³n mejorada con web scraping
python app_v2.py

# O usar el original (sin web scraping)
python app.py
```

La aplicaciÃ³n estarÃ¡ disponible en: `http://localhost:5020`

## ğŸ“ Estructura del Proyecto

```
Auditel-/
â”œâ”€â”€ app_v2.py                 # âœ¨ AplicaciÃ³n mejorada con web scraping
â”œâ”€â”€ app.py                    # AplicaciÃ³n original (respaldo)
â”œâ”€â”€ test_scraping.py          # Script de pruebas
â”‚
â”œâ”€â”€ config/                   # ConfiguraciÃ³n
â”‚   â””â”€â”€ settings.py
â”‚
â”œâ”€â”€ scrapers/                 # MÃ³dulos de web scraping
â”‚   â”œâ”€â”€ base_scraper.py
â”‚   â”œâ”€â”€ dof_scraper.py
â”‚   â”œâ”€â”€ tlaxcala_scraper.py
â”‚   â””â”€â”€ scraper_manager.py
â”‚
â”œâ”€â”€ models/                   # Modelos de datos
â”‚   â””â”€â”€ normativa.py
â”‚
â”œâ”€â”€ utils/                    # Utilidades
â”‚   â”œâ”€â”€ cache_manager.py
â”‚   â””â”€â”€ text_processor.py
â”‚
â”œâ”€â”€ data/                     # Datos JSON
â”œâ”€â”€ cache_data/               # CachÃ© de web scraping
â”œâ”€â”€ logs/                     # Archivos de log
â””â”€â”€ templates/                # HTML templates
```

## ğŸ”§ API Endpoints

### Consultas Normativas

```bash
POST /ask
{
  "question": "licitaciones obras pÃºblicas",
  "auditoria": "Obra PÃºblica",
  "ente": "Municipal",
  "usar_web_scraping": "true"  # Activar web scraping
}
```

### Estado del Sistema

```bash
GET /health
```

### GestiÃ³n de CachÃ©

```bash
# Ver estadÃ­sticas
GET /cache/stats

# Limpiar cachÃ©
POST /cache/clear
```

### Prueba de Web Scraping

```bash
POST /scraping/test
{
  "query": "obras pÃºblicas",
  "fuente": "all"  # o "dof", "tlaxcala"
}
```

## ğŸ§ª Pruebas

```bash
# Ejecutar todas las pruebas
python test_scraping.py

# Pruebas individuales
python -c "from utils.text_processor import TextProcessor; tp = TextProcessor(); print(tp.sanitizar_html('<p>Test</p>'))"
```

## ğŸ“– DocumentaciÃ³n Completa

Ver [MEJORAS.md](MEJORAS.md) para:
- Detalles de implementaciÃ³n
- GuÃ­a de uso avanzado
- ComparaciÃ³n antes/despuÃ©s
- Posibles expansiones futuras

## ğŸ› ï¸ ConfiguraciÃ³n

Edita `config/settings.py` para ajustar:
- Timeouts de scraping
- ExpiraciÃ³n de cachÃ©
- URLs de fuentes
- LÃ­mites de bÃºsqueda
- Y mÃ¡s...

## ğŸ› SoluciÃ³n de Problemas

### El web scraping no funciona
- Verificar conectividad a internet
- Revisar logs en `logs/auditel.log`
- Los sitios web pueden haber cambiado estructura

### CachÃ© no se guarda
- Verificar permisos en directorio `cache_data/`
- Revisar espacio en disco

### Errores de importaciÃ³n
- Asegurar que todas las dependencias estÃ¡n instaladas
- Ejecutar `pip install -r requirements.txt`

## ğŸ“Š CaracterÃ­sticas v3.0

âœ… Web scraping funcional de fuentes oficiales
âœ… BÃºsqueda hÃ­brida (local + web)
âœ… CachÃ© inteligente con persistencia
âœ… Procesamiento avanzado de texto
âœ… ExtracciÃ³n de referencias legales
âœ… Arquitectura modular escalable
âœ… API REST completa
âœ… Sistema de pruebas incluido
âœ… Logging estructurado
âœ… Manejo robusto de errores

## ğŸ”® PrÃ³ximas Funcionalidades

- [ ] MÃ¡s fuentes de scraping (CÃ¡mara de Diputados, SCJN)
- [ ] Base de datos SQL para mejor rendimiento
- [ ] IntegraciÃ³n con OpenAI para anÃ¡lisis profundo
- [ ] Dashboard con estadÃ­sticas
- [ ] Alertas de nuevas normativas
- [ ] ExportaciÃ³n a PDF/Word
- [ ] API GraphQL

## ğŸ“ Licencia

[Especificar licencia]

## ğŸ‘¥ Contribuir

Las contribuciones son bienvenidas. Por favor:
1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## ğŸ“ Soporte

Para problemas o sugerencias, abrir un issue en GitHub

